11주차 정리노트
-김성영, 최정환

이번 강의에서는 비지도 학습에 대해서 학습하였다.
비지도 학습은 이제까지 배워왔던 지도학습들에 비하여 레이블이 없이 사용이 가능하다. 
이에 얀 르쿤은 전체적인 빵을 비지도 학습에, 그 위에 얹는 크림을 지도 학습에, 그리고 장식하는 체리를 강화 학습에 비유하며 비지도 학습에 대해서 말하기도 하였다.

첫번째로 비슷한 샘플끼리 그룹으로 할당하는 군집에 대해서 학습하였다. 
이 군집을 나누기 위해서 k-평균이라는 알고리즘을 사용한다.
k-평균 알고리즘은 알고리즘을 몇 번 반복하는 것만으로도 빠르게 군집을 묶어 구분하여주는 알고리즘이다. 
알고리즘을 반복하는 동안 계속해서 군집들이 모여있는 중심들을 찾아가서 결국에는 군집의 중앙에 결과값을 나타낸다. 
여기서 군집별로 샘플의 평균을 계산하여 새로운 센트로이드를 지정한다는 부분에서 의문이 생겼었다. 
어떤 값을 명목으로 처음 정해졌던 중앙이 인근 랜덤한 샘플과의 거리의 평균으로 이 부분이 중앙과 어울리지 않으니 
다른 더 나은 곳으로 이동하자라는 결과가 나왔는지 조원과 같이 의논해보았다.
 
그렇게 의논한 결과 어쨌든 중앙이라고 생각했던 위치의 점은 랜덤한 샘플을 검사하였을 때 
특정한 위치의 샘플들의 수나 그 위치의 평균값들이 일정하게 나와야하지만 그렇지 않았기에 더 알맞는 위치로 이동한다고 의논하였다.

이 알고리즘은 운이 나쁘다면 처음 정해지는 중앙이 예상치 못 하게 나쁘게 지정되었을 경우 원하는 위치가 나오지 못 할수도 있다. 
또한 군집의 크기가 다르면 잘 작동하지 않는 점도 있다. 
또한 클러스터의 개수를 사용자가 미리 지정해야하며 구해야하는 군집의 형태가 원형이 아닐경우에도 작동이 원활하지 않을 수 있다.

뒤이어 가우시안 혼합모델에 대해서도 학습하였다. 
가우시안 혼합모델은 읽어야하는 샘플이 파라미터가 알려지지 않은 여러 개의 혼합된 가우시안 분포에서 생성되었다고 가정하는 확률 모델이다. 
이는 이전에 학습하였던 k평균에서는 잘 구하지 못하였던 타원형 모양에 대해서 파악할 수 있다. 
이제 가우시안 혼합모델도 k-평균과 마찬가지로 클러스터의 개수를 지정해야하는데 k-평균에서 사용하였던 관성이나 
실루엣 점수는 원형일 때 사용하기 가장 좋기에 타원형일 때 파악하는 가우시안 혼합모델에는 어울리지 않아 AIC와 BIC를 사용하여 군집수를 파악한다. 
하지만 이 모델 또한 타원형 이외의 모양을 가진 데이터셋에는 성능이 좋지 않다.
