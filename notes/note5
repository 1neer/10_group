7주차 정리노트
최정환_김성영

먼저 이번주는 결정트리와 앙상블 학습에 대해서 배웠다.
이 결정트리는 사이킷런의 DecisioonTreeClassifier 모델을 활용해 학습을 할 수 있는데,
이 학습에서는 max_depth라는 하이퍼 파라미터가 활용된다. 이것은 결정트리의 최대 깊이를 지정할 수 있는데,
max_depth값을 늘리고, 학습 결과를 시각화 하여보니 깊이가 max_depth의 값 만큼 깊어지지 않아서 서로 의견을 나누어본 결과,
gini라는 노드의 불순도 측정값이 0이 되면 더 이상 학습을 할 필요가 없으니 더이상 깊어지지 않는다고 추론하였다.

그렇다면 max_depth값은 무조건 크게하면 좋은것 아닌가 라는 의견에는 그렇게 된다면 학습 데이터에 대해 과대적합이 되어
실제 데이터를 예측할 때에는 성능이 더 낮게 나올수 있을 것 이라고 의견을 나누었다.

그 다음에는 DecisionTreeClassifier의 규제 메개변수(하이퍼 파라미터)에 대해 배웠고, 이를 적절하게 조정해서 학습해야
실제 데이터를 예측할 때, 성능의 더 좋게 나온다는 것을 배웠다. 하지만, 문제는 이러한 하이퍼 파라미터의 종류가 많고,
이를 일일이 보고 조정하기에는 시간이 너무 오래걸린다는 점이 있었다.
이 문제에 대해 서로 이야기 해 본 결과, 그리드 서치라는 사이킷런에서 지원하는 모델을 사용하여 최적의 하이퍼 파라미터 값을
찾을 수 있다는 것을 알았고, 이를 이용해 실제로 최적의 하이퍼 파라미터값을 찾는 연습 문제로 풀어보았었다.

마지막으로는 결정트리는 여러용도로 사용가능하고, 성능이 매우 우수하지만 훈련세트에 민감하다는 단점이 있는데
먼저 훈련세트의 회전에 민감해서 조금만 회전시켜도 완벽하게 학습은 하지만 모델을 일반화하기 어렵다는 점이 있고
훈련세트의 작은 변화에 매우 민감해서 하나의 샘플만 달라지더라도 학습시킬 때 매우 다르게 학습할 수 있다는것을 배웠다.
